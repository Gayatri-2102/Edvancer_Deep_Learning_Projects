{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file = '../input/spam-data/train.csv'\ndataset = pd.read_csv(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def to_lower(word):\n#     result = word.lower()\n#     return result\n\n# def remove_special_characters(word):\n#     result= word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n#     return result\n\n# def remove_stop_words(words):\n#     result = [i for i in words if i not in ENGLISH_STOP_WORDS]\n#     return result\n\n# def remove_hyperlink(word):\n#     return re.sub(r\"http\\S+\", \"\", word)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\ntexts = []\nfor i in range(0,1500):\n    mail = re.sub('[^a-zA-Z]',' ',dataset['question_text'][i])\n    mail = mail.lower()\n    mail = mail.split()\n    ps = PorterStemmer()\n    mail = [ps.stem(word) for word in mail \n            if not word in set(stopwords.words('english','french'))]\n    mail = ' '.join(mail)\n    texts.append(mail)\n    print(texts)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nx = cv.fit_transform(texts).toarray()\ny = dataset.iloc[:1500,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y[1:1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nx_train = pad_sequences(x_train,maxlen=40)\nx_test = pad_sequences(x_test,maxlen=40)\n\n# from sklearn.preprocessing import LabelEncoder\n# le = LabelEncoder()\n# y_train = le.fit_transform(y_train)\n# y_test = le.transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom tensorflow.compat.v1.keras.layers import CuDNNGRU\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\n\n#size of the output vector from each layer\nembedding_vector_length = 32\n\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_feature = 1500\n#Creating a sequential model\nmodel = tf.keras.Sequential()\n\n#Creating an embedding layer to vectorize\nmodel.add(Embedding(max_feature, embedding_vector_length, input_length=40))\n\n#Addding Bi-directional LSTM\nmodel.add(Bidirectional(tf.keras.layers.LSTM(64)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Relu allows converging quickly and allows backpropagation\nmodel.add(Dense(16, activation='relu'))\n\n#Deep Learninng models can be overfit easily, to avoid this, we add randomization using drop out\nmodel.add(Dropout(0.1))\n\n#Adding sigmoid activation function to normalize the output\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())\n\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train, batch_size=512, epochs=20, validation_data=(x_test, y_test))\n\ny_predict = [1 if o>0.5 else 0 for o in model.predict(x_test)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score\n\ncf_matrix =confusion_matrix(y_test,y_predict)\n\nprint(cf_matrix)\n\nscore =accuracy_score(y_test,y_predict)\n\nprint(score)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}